# 多线程

---

<br>

## 1. 变量传递和访问函数

---

### 1.1 如何给线程函数传递参数

> 多线程引用参数的问题

```c++
// 这里有一个 & 但是对于多线程来说，其实已经被释放掉了，所以会报错
void show_sth(std::string & sth) {
    std::cout << "Hello, " << sth << std::endl;
}

int main(int, char **) {
	  // 临时变量释放的早
    std::thread t1(show_sth, "World");
  
  	t1.join();
    return 0;
}
```

### 1.2 如何传递一个类的函数给线程

> 多线程如何传递一个类函数

```c++
class demo {
    public:
    void say_hello() { std::cout << "Hello World!" << std::endl; }
};

int main() {
    // 使用智能指针的原因就是害怕提前释放
    // 因为是先传递参数给 thread，然后再使用，如果在 join() 前释放了那么，线程就调用空的了
    auto p1 = std::make_unique<demo>();

    // 正确传递 p1 对象给线程
    std::thread t1(&demo::say_hello, p1.get());  // 传递裸指针

    t1.join();

    return 0;
}
```

### 1.3 如何传递类的私有函数给线程

> 类内私有函数的使用

```c++
class demo {
private:
    friend void thread_func();		// 如果想要这个私有的成员函数，需要借助友元的帮助
    void inside() { std::cout << "Hello World! but inside" << std::endl; }
};

// 使用这个类的有元函数，访问类内函数
void thread_func() {
    auto p2 = std::make_unique<demo>();

    std::thread t(&demo::inside, p2.get());
    t.join();
}

int main() {
    thread_func();

    return 0;
}
```



## 2. 互斥锁

---

### 2.1 对变量的抢夺问题

> 两个线程抢夺同一个数据变量，导致数据写入不正常
>
> 你会发现结果不是 20w

```c++
int a = 0;

void func() {
    for (int i = 0; i < 100000; i++) {
        a++;
    }
}

int main() {
    // 两个同时抢夺一个变量
    std::thread t1(&func);
    std::thread t2(&func);

    t1.join(); t2.join();

    std::cout << a << std::endl;

    return 0;
}
```

### 2.2 线程锁和锁定的锁定区域

> 应该设置，当一个线程在访问一个便利变量的时候，其他的线程不允许访问
>
> 那么我们应该设置，线程锁
>
> **控制的范围一般都是，lock 到 unlock 之间的变量**

```c++
std::mutex m;
void func() {
    for (int i = 0; i < 100000; i++) {
        m.lock();   // 加锁
        a++;
        m.unlock();	// 解锁
    }
}
```

### 2.3 多线程锁的死锁问题

> **死锁问题**：指多个进程或线程由于相互竞争资源并形成循环等待，导致它们都无法继续执行的状态
>
> 下面这个案例，你只会看到上锁，但是永远开看不到开锁

```c++
std::mutex mutexA;
std::mutex mutexB;

void thread1() {
    // 手动先锁定 mutexA，再锁定 mutexB
    mutexA.lock();
    std::cout << "Thread 1 locked mutexA" << std::endl;

    std::this_thread::sleep_for(std::chrono::milliseconds(100));

    mutexB.lock();
    std::cout << "Thread 1 locked mutexB" << std::endl;

    // 解锁
    mutexB.unlock();
    mutexA.unlock();
}

void thread2() {
    // 手动先锁定 mutexB，再锁定 mutexA
    mutexB.lock();
    std::cout << "Thread 2 locked mutexB" << std::endl;

    std::this_thread::sleep_for(std::chrono::milliseconds(100));

    mutexA.lock();
    std::cout << "Thread 2 locked mutexA" << std::endl;

    // 解锁
    mutexA.unlock();
    mutexB.unlock();
}

int main() {
    // 第一个线程跑起来的时候等待了一会，锁住了 A
    // 第一个线程休息，还没有到释放，然后第二个线程锁住了 B
    // 这个时候休息结束了，第一个线程要去锁 B了，但是第二个线程已经锁 B 了，于是对峙
    std::thread t1(thread1);
    std::thread t2(thread2);

    t1.join();
    t2.join();

    return 0;
}
```

<br>

## 3. std::lock_guard 和 lock_unique 模板

---

### 3.1 锁类的基本使用

> 这两个东西和 **智能指针** 特别像，一个是省去了手动释放内存这个事情，另一个就是省去了解锁的事
>
> 其实你能够发现，我们的大多数线程锁，要保护的是变量，而大多数变量都是在函数内部操作的，所以锁的范围就是随着这个函数结束了，我们差不多可以释放锁了
>
> 所以我们可以构建一个一个类，获取这个锁然后自动关上锁，随着函数结束，调用析构函数释放锁

```c++
std::mutex mutexA;

void thread1(int &a) {
    // 使用 lock_guard 自动锁定和解锁 mutexA
    std::lock_guard<std::mutex> lock(mutexA);
    std::cout << "Thread 1 is running" << std::endl;

    a++;
    // 离开作用域时 lock_guard 自动解锁
}

void thread2(int &a) {
    // 使用 lock_guard 自动锁定和解锁 mutexA
    std::lock_guard<std::mutex> lock(mutexA);
    std::cout << "Thread 2 is running" << std::endl;

    a++;
    // 离开作用域时 lock_guard 自动解锁
}

int main() {
    int a = 0;
    std::thread t1(thread1, std::ref(a));
    std::thread t2(thread2, std::ref(a));

    t1.join();
    t2.join();

    std::cout << a << std::endl;

    return 0;
}
```

> 那 **unique_lock** 是提供了非常多的操作，因为 **lock_guard** 也就提供了一个加锁解锁，自己也能做
>
> 譬如说：延迟加锁、超时、条件变量

### 3.2 延迟加锁

```c++
// 延迟加锁
bool try_lock_for(const std::chrono::duration& rel_time);
```

> 最主要的原因，譬如我们之前的死锁操作就是，两个对峙的情况，因为两个一直在请求，但是互相请求不到
>
> 但是时间是无限长的一直请求，如果两个人有一个人哈，稍微退让一下，过几秒之后再请求就解决了
>
> **所以上面的函数相当于说：指定时间内尝试获取锁，从而避免长时间阻塞**

```c++
// 实现一下延迟加锁的操作 
std::timed_mutex mtx;

void try_to_get_lock(int thread_id) {
    // 尝试在 1 秒内获取锁
    if (mtx.try_lock_for(std::chrono::seconds(1))) {
        std::cout << "Thread " << thread_id << " got the lock." << std::endl;
        std::this_thread::sleep_for(std::chrono::seconds(2));  // 模拟工作
        mtx.unlock();  // 解锁
    } 
    // 没在制定时间拿到锁的后续操作
    else {
        std::cout << "Thread " << thread_id <<
            " could not get the lock within 1 second." << std::endl;
    }
}

int main() {
    std::thread t1(try_to_get_lock, 1);
    std::this_thread::sleep_for(std::chrono::milliseconds(500));  // 确保线程1先运行
    std::thread t2(try_to_get_lock, 2);

    t1.join();
    t2.join();

    return 0;
}
```

> 这里我们改进一下，让 unique_lock 一起帮着实现，避免手动释放锁

```c++
std::timed_mutex mtx;

void try_to_get_lock(int thread_id) {
	std::unique_lock<std::timed_mutex> lg(mtx, std::defer_lock); 	// defer_lock 避免自动上锁
    // 尝试在 1 秒内获取锁
    if (mtx.try_lock_for(std::chrono::seconds(1))) {
        std::cout << "Thread " << thread_id << " got the lock." << std::endl;
        std::this_thread::sleep_for(std::chrono::seconds(2));  // 模拟工作
		// 这里不需要手动释放了
    } 
    // 没在制定时间拿到锁的后续操作
    else {
        std::cout << "Thread " << thread_id <<
            " could not get the lock within 1 second." << std::endl;
    }
}
```



## ==4. 多线程多单例设计模式的影响==

---

> 对于创建实例，尽管我们是单例模式，但是多线程仍有可能创建两个不同的实例

```c++
#include <iostream>
#include <thread>

class log {
public:
    // 禁止拷贝构造和赋值构造函数
    log(const log &log) = delete;
    log &operator=(const log &log) = delete;

    // 饿汉模式
    static log &get_instance1() {
        static log *instance = nullptr;

        if (!instance) instance = new log();

        return *instance;
    }

    // 传入需要打印的信息
    void printLog(const std::string &msg) {
        std::cout << __TIME__ << " -- " << msg << " -- Instance Address: " << this << std::endl;
    }

private:
    log() = default;
};

void func() {
    log::get_instance1().printLog("thread");
}

int main() {
    // 多线程创建的实例，输出的地址有可能是一样的
    std::thread t1(func);
    std::thread t2(func);

    t1.join();
    t2.join();

    // 单例模式的 address 是一样的
    log::get_instance1().printLog("class1");
    log::get_instance1().printLog("class2");

    return 0;
}
```

```shell
# 多线程调用单例模式生成
17:50:55 -- thread -- Instance Address: 0x600000924070
17:50:55 -- thread -- Instance Address: 0x600000928000
# 单例模式生成
17:50:55 -- class1 -- Instance Address: 0x600000928000
17:50:55 -- class2 -- Instance Address: 0x600000928000
```

> 解决方法，对于某一个部分的代码，在多线程的时候，就确保他只调用一次
>
> ` call_once()` 函数，需要一个 `std::once_flag` 作为第一个参数，和一个被包装的代码（函数、lambda 函数）确保这个部分的代码在多个线程发生只执行一次

```c++
// 获取单例实例
static Singleton& getInstance() {
    // 使用 std::call_once 确保实例只会初始化一次
    std::call_once(initOnceFlag, []() {
        instance = new Singleton();
    });
    return *instance;
}
```

```c++
class Singleton {
public:
    // 禁止拷贝构造和赋值构造函数
    Singleton(const Singleton&) = delete;
    Singleton& operator=(const Singleton&) = delete;

    // 获取单例实例
    static Singleton& getInstance() {
        // 使用 std::call_once 确保实例只会初始化一次
        std::call_once(initOnceFlag, []() {
            instance = new Singleton();
        });
        return *instance;
    }

    // 打印信息
    void printMessage(const std::string& msg) {
        std::cout << "Message: " << msg << " -- Instance Address: " << this << std::endl;
    }

private:
    Singleton() = default;
    static Singleton* instance;
    static std::once_flag initOnceFlag;
};

// 静态变量初始化
Singleton* Singleton::instance = nullptr;
std::once_flag Singleton::initOnceFlag;

void threadFunc() {
    Singleton::getInstance().printMessage("Hello from thread");
}

int main() {
    // 创建两个线程
    std::thread t1(threadFunc);
    std::thread t2(threadFunc);

    t1.join();
    t2.join();

    return 0;
}
```



## 5. 条件变量

---

### 5.1 wait()

> `std::condition_variable::wait` 是在多线程同步中非常重要的一个工具，它能够让线程在某个条件未满足的情况下自动进入等待状态，避免忙等待（busy waiting）的问题

```c++
std::queue<int> que;
std::condition_variable g_cv;
std::mutex mtx;

void producer() {
    // 加任务
    for (int i = 0; i < 10; i++) {
        std::lock_guard<std::mutex> lg(mtx);
        que.push(i);
        std::cout << "Task: " << i << std::endl;
    }
}

void consumer() {
    // 不断的获取任务
    while (true) {
        std::unique_lock<std::mutex> ul(mtx);
        // 如果队列为空的话，需要等待
        g_cv.wait(ul, []() { return !que.empty(); });
        int val = que.front();
        que.pop();
    }
}
```

> 看上面的模型，又一个**任务队列**，生产者会一直在里面加任务，消费者会一个读取任务来做，但是如果两个线程对一个队列变量读取没有锁的话可能会出问题，于是乎我们加了锁
>
> 但是还有一个问题就是如果生产和消费的出入流水不对等，就可能会有消费太快，即队列为空的问题，这个时候如果读任务的锁住了变量，那么加任务的就无法加入了，导致死循环
>
> 所以对于没有任务的时候，遇到了读取任务的情况，这个就是 OS 经典的 等待，等到有资源了再去执行，在执行之前，虽然拿着锁，但是还是让别人先去，即 `std::condition_variable::wait` 方法实现的效果

```c++
/*
作用：在调用 wait() 时，条件变量会自动释放互斥锁 lock，使其他线程能够访问共享资源（如任务队列）。
当条件满足时，线程被唤醒，wait() 会重新获得互斥锁 lock，从而继续访问共享资源。
*/

// 带有谓词
template<class Predicate>
void wait(std::unique_lock<std::mutex>& lock, Predicate pred);
```

`Predicate pred`：这是一个 **谓词**，即返回 `bool` 类型的函数或 lambda 表达式。

- **作用**：谓词用于检查条件是否已经满足。线程在唤醒后会调用这个谓词，只有当返回值为 `true` 时，线程才会继续执行。否则，线程将继续等待。

### 5.2 notify_x() 

> 我们的进程陷入了等待，那么自然也得有人告诉他有资源了，可以不用等了
>
> 于是有了：`notify_one()` & `notify_all()`

```c++
#include "include/stdc++.h"

std::queue<int> que;
std::condition_variable g_cv;
std::mutex mtx;
bool stop = false; // 停止标志

void producer() {
    // 加任务
    for (int i = 0; i < 10; i++) {
        {	// 局部作用域
            std::lock_guard<std::mutex> lg(mtx);
            que.push(i);
            g_cv.notify_one(); // 通知可以不需要等待了
            std::cout << "Producer: " << i << std::endl;
        }
        // 延迟时间可以调整，减少甚至去掉
        std::this_thread::sleep_for(std::chrono::milliseconds(1)); // 可根据需要调整
    }

    // 生产结束后，通知消费者退出
    {
        std::lock_guard<std::mutex> lg(mtx);
        stop = true;
        g_cv.notify_all(); // 通知所有消费者
    }
}

void consumer() {
    while (true) {
        std::unique_lock<std::mutex> ul(mtx);
        // 等待队列不为空或者 stop 为 true
        g_cv.wait(ul, []() { return !que.empty() || stop; });

        if (!que.empty()) {
            const int val = que.front();
            que.pop();
            std::cout << "Consumer: " << val << std::endl;
        }
        else if (stop) {
            break;
        }
        // 调整消费的延迟，根据实际场景需要
        std::this_thread::sleep_for(std::chrono::milliseconds(5)); // 延迟也可以去掉或改短
    }
}

int main() {
    std::thread t_producer(producer);
    std::thread t_consumer(consumer);

    t_producer.join();
    t_consumer.join();

    return 0;
}
```

> 中间出现了很多 `{}` 的代码块，作用就是为了限制 lock 的范围，不影响到别的范围
>
> 有这个局部作用于存在的话，那么 lock 的影响范围就只在这个块中，随着这个块结束，就释放这锁，允许被访问

```c++
{
	std::lock_guard<std::mutex> lg(mtx);
	stop = true;
	g_cv.notify_all(); // 通知所有消费者
}
```



## ==6. 线程池==

---

> 我们之间创建线程都是单独的
>
> `std::thread t(func)`，在线程池中，就是创建了一个 `vector<std::thread> threads` **线程容器**
>
> 线程成了一个数组，即池，创建一个类的话，更加集成统一功能

```c++
class ThreadPool {
public:
    ThreadPool(const ThreadPool & other) = delete;
    ThreadPool operator=(const ThreadPool & other) = delete;

    static ThreadPool& get_instance(int thread_num) {
        std::call_once(once, [&thread_num]() {
            instance.reset(new ThreadPool(thread_num));
        });
        return *instance;
    }

    template<class F, class ...Args>
    void add_task(F && func, Args... args) {
        auto task = std::bind(std::forward<F>(func), std::forward<Args>(args)...);
        {
            std::unique_lock lock(this->_mtx);
            tasks.emplace(std::move(task));
        }
        this->condition.notify_one();
    }

    ~ThreadPool() {
        {
            std::unique_lock lock(this->_mtx);
            this->stop = true;
        }

        this->condition.notify_all();

        // 还在等待的线程全部都等他们执行完
        for (std::thread & t : threads) {
            if (t.joinable()) t.join();
        }
    }

private:    
    explicit ThreadPool(const int & thread_num) {
        // 往线程池的线程塞入线程函数
        for (int i = 0; i < thread_num; i++){
            // emplace 会生成一个 thread 的，所以我们填的参数其实是线程里的函数
            threads.emplace_back(&ThreadPool::thread_exec, this);       // 写法一
            // 感觉效率低一些，就是传入了 lambda 函数，lambda函数再使用 thread_exec 函数效率低
            // threads.emplace_back([this](){ thread_exec(); });          // 写法二
        }
    }

    void thread_exec() {
        while (true) {
            std::function<void()> task;
            {
                std::unique_lock lock(_mtx);
                condition.wait(lock, [this]() {return stop || !tasks.empty();});

                if (stop and tasks.empty()) return;

                if (!tasks.empty()) {
                    task = tasks.front();
                    tasks.pop();
                }
            }
            task();
        }
    }


    bool stop = false;
    std::mutex _mtx;
    static std::once_flag once;
    static std::unique_ptr<ThreadPool> instance;
    std::condition_variable condition;

    std::vector<std::thread> threads;
    std::queue<std::function<void()>> tasks;
};

std::unique_ptr<ThreadPool> ThreadPool::instance = nullptr;
std::once_flag ThreadPool::once;



int main() {
    auto &p = ThreadPool::get_instance(2);
	// 保护 cout 正常输出
    std::mutex cout_mtx;
    
    for (int i = 0; i < 100; i++) {
        p.add_task([i, &cout_mtx]() {
            std::unique_lock lock(cout_mtx);
            std::cout << "The Task " << i << " is running!\n";
        });
        std::this_thread::sleep_for(std::chrono::microseconds(1000));
    }

    return 0;
}
```

<br>

## 7. 异步并发

---

> `std::packaged_task` 和 `std::future`、`std::promise` 等构成了 C++ 中实现异步编程和并发操作的机制
>
> `std::future` 的作用
>
> - 与 `std::async` 搭配使用：用来简化异步函数调用，并获取返回结果。
>
> - 与 `std::packaged_task` 或 `std::promise` 搭配使用：实现更加灵活的任务管理和结果获取。
>
> - 多线程编程：通过 `std::future` 可以方便地获取不同线程中任务的返回值。

### 7.1 `std::async`

> 你只需要调用 `std::async`，它会帮你自动处理线程创建和任务管理，基本啥都不用你管

```c++
int func() {
    int ret = 0;

    for (size_t i = 0; i < 1000; i++) ret ++;
    return ret;
}

int main() {
    // 当 func 传递到 future 的时候，后台就开了一个线程运行 func 了
    std::future<int> future_ret = std::async(std::launch::async, func);

    // 主程序干事情
    std::cout << func() << std::endl;

    // get() 方法如果这个函数有返回值的话
    std::cout << future_ret.get() << std::endl;

    return 0;
}
```

### 7.2 `std::packaged_task`

> 包装一个可调用对象，并将它转换为异步任务
>
> 把一个函数包装成可执行的异步任务之后，分成两个部分
>
> 1. 转交给 future 来获取函数返回值
> 2. 移交给一个线程用于执行函数

```c++
int main() {
    // 1. 创建一个 std::packaged_task，并包装 func
    std::packaged_task<int(void)> task(func);

    // 2. 获取与 task 相关联的 std::future
    std::future<int> result = task.get_future();

    // 3. 将任务交给一个线程去执行
    std::thread task_thread(std::move(task));

	// 4. 这里我们可以干一些主线程的事情
    std::cout << func() << std::endl;

	// 5. 等待任务完成并获取结果
    // result.get() 会阻塞线程一直到结束
    std::cout << "result: " << result.get() << std::endl;
	
    // 6. 等待线程结束
    if (task_thread.joinable()) task_thread.join();

    return 0;
}
```

### 7.3 `std::promise`

> 不同线程之间值的传递：许一个线程（生产者）设置一个值，另一个线程（消费者）通过 `std::future` 来获取这个值。
>
> 它是 `std::future` 的补充，提供了一种手动设置任务结果的方式
>
> 通常使用 `std::promise` 来创建共享状态，并将它与 `std::future` 关联。
>
> 生产者线程通过 `promise` 设置值，而消费者线程通过 `future` 获取这个值

```c++
// 这个函数模拟一个耗时操作，并设置 promise 的值
void slow_function(std::promise<int>& prom) {
    std::this_thread::sleep_for(std::chrono::seconds(1));  // 模拟耗时操作
    prom.set_value(42);  // 设置任务的结果，传递给 future
}

int main() {
    // 1. 创建一个 std::promise 对象
    std::promise<int> prom;

    // 2. 通过 promise 获取关联的 future
    std::future<int> fut = prom.get_future();

    // 3. 启动一个线程并传递 promise 对象
    std::thread producer_thread(slow_function, std::ref(prom));

    // 4. 在主线程中，等待 future 获取结果
    std::cout << "Waiting for the result..." << std::endl;
    int result = fut.get();  // 阻塞，直到 promise 设置了结果
    std::cout << "Result: " << result << std::endl;  // 输出 42

    // 5. 等待生产者线程结束
    producer_thread.join();

    return 0;
}
```



## 8. 原子操作

---

### `std::atomic`

> **线程安全**：`std::atomic` 确保对变量的读写操作不会被打断，从而避免多个线程并发访问时的竞争问题。
>
> **无需锁机制**：原子操作可以避免使用互斥锁（如 `std::mutex`），从而提高并发性能，因为锁通常会导致性能瓶颈。
>
> **无法替代复杂同步机制**：原子操作适合解决简单的读写问题，但是对于更复杂的同步问题（如管理多个资源、条件变量等），依然需要使用锁等同步机制。
>
> **平台依赖**：原子操作的性能依赖于底层硬件和平台，有些平台对某些原子操作的支持不够好，可能会导致性能瓶颈。

```c++
void func(std::atomic<int>& change_data) {
    for (size_t i = 0; i < 10000; i++) {
        change_data++;
    }
}

static std::atomic<int> shared_data(0);

int main() {
    // 创建两个线程
    std::thread t1(func, std::ref(shared_data));
    std::thread t2(func, std::ref(shared_data));

    // 等待线程完成
    t1.join();
    t2.join();

    // 输出结果 [atomic.load()]
    std::cout << "Final shared_data value: " << shared_data.load() << std::endl;

    return 0;
}
```

<br>