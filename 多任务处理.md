# 多任务处理

---

<br>

## 1. 变量传递和访问函数

---

### 1.1 如何给线程函数传递参数

> 多线程引用参数的问题

```c++
// 这里有一个 & 但是对于多线程来说，其实已经被释放掉了，所以会报错
void show_sth(std::string & sth) {
    std::cout << "Hello, " << sth << std::endl;
}

int main(int, char **) {
	  // 临时变量释放的早
    std::thread t1(show_sth, "World");
  
  	t1.join();
    return 0;
}
```

### 1.2 如何传递一个类的函数给线程

> 多线程如何传递一个类函数

```c++
class demo {
    public:
    void say_hello() { std::cout << "Hello World!" << std::endl; }
};

int main() {
    // 使用智能指针的原因就是害怕提前释放
    // 因为是先传递参数给 thread，然后再使用，如果在 join() 前释放了那么，线程就调用空的了
    auto p1 = std::make_unique<demo>();

    // 正确传递 p1 对象给线程
    std::thread t1(&demo::say_hello, p1.get());  // 传递裸指针

    t1.join();

    return 0;
}
```

### 1.3 如何传递类的私有函数给线程

> 类内私有函数的使用

```c++
class demo {
private:
    friend void thread_func();		// 如果想要这个私有的成员函数，需要借助友元的帮助
    void inside() { std::cout << "Hello World! but inside" << std::endl; }
};

// 使用这个类的有元函数，访问类内函数
void thread_func() {
    auto p2 = std::make_unique<demo>();

    std::thread t(&demo::inside, p2.get());
    t.join();
}

int main() {
    thread_func();

    return 0;
}
```



## 2. 互斥锁

---

### 2.1 对变量的抢夺问题

> 两个线程抢夺同一个数据变量，导致数据写入不正常
>
> 你会发现结果不是 20w

```c++
int a = 0;

void func() {
    for (int i = 0; i < 100000; i++) {
        a++;
    }
}

int main() {
    // 两个同时抢夺一个变量
    std::thread t1(&func);
    std::thread t2(&func);

    t1.join(); t2.join();

    std::cout << a << std::endl;

    return 0;
}
```

### 2.2 线程锁和锁定的锁定区域

> 应该设置，当一个线程在访问一个便利变量的时候，其他的线程不允许访问
>
> 那么我们应该设置，线程锁
>
> **控制的范围一般都是，lock 到 unlock 之间的变量**

```c++
std::mutex m;
void func() {
    for (int i = 0; i < 100000; i++) {
        m.lock();   // 加锁
        a++;
        m.unlock();	// 解锁
    }
}
```

### 2.3 多线程锁的死锁问题

> **死锁问题**：指多个进程或线程由于相互竞争资源并形成循环等待，导致它们都无法继续执行的状态
>
> 下面这个案例，你只会看到上锁，但是永远开看不到开锁

```c++
std::mutex mutexA;
std::mutex mutexB;

void thread1() {
    // 手动先锁定 mutexA，再锁定 mutexB
    mutexA.lock();
    std::cout << "Thread 1 locked mutexA" << std::endl;

    std::this_thread::sleep_for(std::chrono::milliseconds(100));

    mutexB.lock();
    std::cout << "Thread 1 locked mutexB" << std::endl;

    // 解锁
    mutexB.unlock();
    mutexA.unlock();
}

void thread2() {
    // 手动先锁定 mutexB，再锁定 mutexA
    mutexB.lock();
    std::cout << "Thread 2 locked mutexB" << std::endl;

    std::this_thread::sleep_for(std::chrono::milliseconds(100));

    mutexA.lock();
    std::cout << "Thread 2 locked mutexA" << std::endl;

    // 解锁
    mutexA.unlock();
    mutexB.unlock();
}

int main() {
    // 第一个线程跑起来的时候等待了一会，锁住了 A
    // 第一个线程休息，还没有到释放，然后第二个线程锁住了 B
    // 这个时候休息结束了，第一个线程要去锁 B了，但是第二个线程已经锁 B 了，于是对峙
    std::thread t1(thread1);
    std::thread t2(thread2);

    t1.join();
    t2.join();

    return 0;
}
```

<br>

## 3. std::lock_guard 和 lock_unique

---

### 3.1 锁类的基本使用

> 这两个东西和 **智能指针** 特别像，智能指针是省去了手动释放内存这个事情，而`lock_guard`就是省去了打开锁的步骤
>
> 其实你能够发现，我们的大多数线程锁，要保护的是变量，而大多数变量都是在函数内部操作的，所以自动锁的范围就是跟函数的`{}` 一样长
>
> 自动锁类的原理就是，随着函数作用域结束，调用类的析构函数，在析构函数中释放锁

```c++
std::mutex mutexA;

void thread1(int &a) {
    // 使用 lock_guard 自动锁定和解锁 mutexA
    std::lock_guard<std::mutex> lock(mutexA);
    std::cout << "Thread 1 is running" << std::endl;

    a++;
    // 离开作用域时 lock_guard 自动解锁
}

void thread2(int &a) {
    // 使用 lock_guard 自动锁定和解锁 mutexA
    std::lock_guard<std::mutex> lock(mutexA);
    std::cout << "Thread 2 is running" << std::endl;

    a++;
    // 离开作用域时 lock_guard 自动解锁
}

int main() {
    int a = 0;
    std::thread t1(thread1, std::ref(a));
    std::thread t2(thread2, std::ref(a));

    t1.join();
    t2.join();

    std::cout << a << std::endl;

    return 0;
}
```

> 那 **unique_lock** 是提供了非常多的操作，因为 **lock_guard** 也就提供了一个加锁解锁，自己也能做
>
> 譬如说：延迟加锁、超时、条件变量

### 3.2 延迟加锁

```c++
// 延迟加锁
bool try_lock_for(const std::chrono::duration& rel_time);
```

> 最主要的原因，譬如我们之前的死锁操作就是，两个对峙的情况，因为两个一直在请求，但是互相请求不到
>
> 但是时间是无限长的一直请求，如果两个人有一个人哈，稍微退让一下，过几秒之后再请求就解决了
>
> **所以上面的函数相当于说：指定时间内尝试获取锁，从而避免长时间阻塞**

```c++
// 实现一下延迟加锁的操作 
std::timed_mutex mtx;

void try_to_get_lock(int thread_id) {
    // 尝试在 1 秒内获取锁
    if (mtx.try_lock_for(std::chrono::seconds(1))) {
        std::cout << "Thread " << thread_id << " got the lock." << std::endl;
        std::this_thread::sleep_for(std::chrono::seconds(2));  // 模拟工作
        mtx.unlock();  // 解锁
    } 
    // 没在制定时间拿到锁的后续操作
    else {
        std::cout << "Thread " << thread_id <<
            " could not get the lock within 1 second." << std::endl;
    }
}

int main() {
    std::thread t1(try_to_get_lock, 1);
    std::this_thread::sleep_for(std::chrono::milliseconds(500));  // 确保线程1先运行
    std::thread t2(try_to_get_lock, 2);

    t1.join();
    t2.join();

    return 0;
}
```

> 这里我们改进一下，让 unique_lock 一起帮着实现，避免手动释放锁

```c++
std::timed_mutex mtx;

void try_to_get_lock(int thread_id) {
	std::unique_lock<std::timed_mutex> lg(mtx, std::defer_lock); 	// defer_lock 避免自动上锁
    // 尝试在 1 秒内获取锁
    if (mtx.try_lock_for(std::chrono::seconds(1))) {
        std::cout << "Thread " << thread_id << " got the lock." << std::endl;
        std::this_thread::sleep_for(std::chrono::seconds(2));  // 模拟工作
		// 这里不需要手动释放了
    } 
    // 没在制定时间拿到锁的后续操作
    else {
        std::cout << "Thread " << thread_id <<
            " could not get the lock within 1 second." << std::endl;
    }
}
```



## 4. 多线程多单例设计模式的影响

---

> 对于创建实例，尽管我们是单例模式，但是多线程仍有可能创建两个不同的实例

```c++
#include <iostream>
#include <thread>

class log {
public:
    // 禁止拷贝构造和赋值构造函数
    log(const log &log) = delete;
    log &operator=(const log &log) = delete;

    // 饿汉模式
    static log &get_instance1() {
        static log *instance = nullptr;

        if (!instance) instance = new log();

        return *instance;
    }

    // 传入需要打印的信息
    void printLog(const std::string &msg) {
        std::cout << __TIME__ << " -- " << msg << " -- Instance Address: " << this << std::endl;
    }

private:
    log() = default;
};

void func() {
    log::get_instance1().printLog("thread");
}

int main() {
    // 多线程创建的实例，输出的地址有可能是一样的
    std::thread t1(func);
    std::thread t2(func);

    t1.join();
    t2.join();

    // 单例模式的 address 是一样的
    log::get_instance1().printLog("class1");
    log::get_instance1().printLog("class2");

    return 0;
}
```

```shell
# 多线程调用单例模式生成
17:50:55 -- thread -- Instance Address: 0x600000924070
17:50:55 -- thread -- Instance Address: 0x600000928000
# 单例模式生成
17:50:55 -- class1 -- Instance Address: 0x600000928000
17:50:55 -- class2 -- Instance Address: 0x600000928000
```

> 解决方法，对于某一个部分的代码，在多线程的时候，就确保他只调用一次
>
> ` call_once()` 函数，需要一个 `std::once_flag` 作为第一个参数，和一个被包装的代码（函数、lambda 函数）确保这个部分的代码在多个线程发生只执行一次

```c++
// 获取单例实例
static Singleton& getInstance() {
    // 使用 std::call_once 确保实例只会初始化一次
    std::call_once(initOnceFlag, []() {
        instance = new Singleton();
    });
    return *instance;
}
```

```c++
class Singleton {
public:
    // 禁止拷贝构造和赋值构造函数
    Singleton(const Singleton&) = delete;
    Singleton& operator=(const Singleton&) = delete;

    // 获取单例实例
    static Singleton& getInstance() {
        // 使用 std::call_once 确保实例只会初始化一次
        std::call_once(initOnceFlag, []() {
            instance = new Singleton();
        });
        return *instance;
    }

    // 打印信息
    void printMessage(const std::string& msg) {
        std::cout << "Message: " << msg << " -- Instance Address: " << this << std::endl;
    }

private:
    Singleton() = default;
    static Singleton* instance;
    static std::once_flag initOnceFlag;
};

// 静态变量初始化
Singleton* Singleton::instance = nullptr;
std::once_flag Singleton::initOnceFlag;

void threadFunc() {
    Singleton::getInstance().printMessage("Hello from thread");
}

int main() {
    // 创建两个线程
    std::thread t1(threadFunc);
    std::thread t2(threadFunc);

    t1.join();
    t2.join();

    return 0;
}
```



## 5. 条件变量

---

### 5.1 wait()

> `std::condition_variable::wait` 是在多线程同步中非常重要的一个工具，它能够让线程在某个条件未满足的情况下自动进入等待状态，避免忙等待（busy waiting）的问题

```c++
std::queue<int> que;
std::condition_variable g_cv;
std::mutex mtx;

void producer() {
    // 加任务
    for (int i = 0; i < 10; i++) {
        std::lock_guard<std::mutex> lg(mtx);
        que.push(i);
        std::cout << "Task: " << i << std::endl;
    }
}

void consumer() {
    // 不断的获取任务
    while (true) {
        std::unique_lock<std::mutex> ul(mtx);
        // 如果队列为空的话，需要等待
        g_cv.wait(ul, []() { return !que.empty(); });
        int val = que.front();
        que.pop();
    }
}
```

> 看上面的模型，又一个**任务队列**，生产者会一直在里面加任务，消费者会一个读取任务来做，但是如果两个线程对一个队列变量读取没有锁的话可能会出问题，于是乎我们加了锁
>
> 但是还有一个问题就是如果`生产和消费的出入流水不对等`，就可能会有消费太快，即队列为空的问题，队列为空问题不大，但是问题是消费者们会一直来看队列中有没有东西，这种死循环的快速访问对资源消耗是很大的。所以希望
>
> 所以希望能够解决这种CPU轮空，等到有资源了再去执行，在执行之前，即 `std::condition_variable::wait` 这种方案实现的效果

```c++
/*
作用：在调用 wait() 时，条件变量会自动释放互斥锁 lock，使其他线程能够访问共享资源（如任务队列）
当条件满足时，线程被唤醒，wait() 会重新获得互斥锁 lock，从而继续访问共享资源。
*/

// 带有谓词
template<class Predicate>
void wait(std::unique_lock<std::mutex>& lock, Predicate pred);
```

`Predicate pred`：这是一个 **谓词**，即返回 `bool` 类型的函数或 lambda 表达式。

- **作用**：谓词用于检查条件是否已经满足。线程在唤醒后会调用这个谓词，只有当返回值为 `true` 时，线程才会继续执行。否则，线程将继续等待。

### 5.2 notify_x() 

> 我们的进程陷入了等待，那么自然也得有人告诉他有资源了，可以不用等了
>
> 于是有了：`notify_one()` & `notify_all()`

```c++
#include "include/stdc++.h"

std::queue<int> que;
std::condition_variable g_cv;
std::mutex mtx;
bool stop = false; // 停止标志

void producer() {
    // 加任务
    for (int i = 0; i < 10; i++) {
        {	// 局部作用域
            std::lock_guard<std::mutex> lg(mtx);
            que.push(i);
            g_cv.notify_one(); // 通知可以不需要等待了
            std::cout << "Producer: " << i << std::endl;
        }
        // 延迟时间可以调整，减少甚至去掉
        std::this_thread::sleep_for(std::chrono::milliseconds(1)); // 可根据需要调整
    }

    // 生产结束后，通知消费者退出
    {
        std::lock_guard<std::mutex> lg(mtx);
        stop = true;
        g_cv.notify_all(); // 通知所有消费者
    }
}

void consumer() {
    while (true) {
        std::unique_lock<std::mutex> ul(mtx);
        // 等待队列不为空或者 stop 为 true
        g_cv.wait(ul, []() { return !que.empty() || stop; });

        if (!que.empty()) {
            const int val = que.front();
            que.pop();
            std::cout << "Consumer: " << val << std::endl;
        }
        else if (stop) {
            break;
        }
        // 调整消费的延迟，根据实际场景需要
        std::this_thread::sleep_for(std::chrono::milliseconds(5)); // 延迟也可以去掉或改短
    }
}

int main() {
    std::thread t_producer(producer);
    std::thread t_consumer(consumer);

    t_producer.join();
    t_consumer.join();

    return 0;
}
```

> 中间出现了很多 `{}` 的代码块，作用就是为了限制 lock 的范围，不影响到别的范围
>
> 有这个局部作用于存在的话，那么 lock 的影响范围就只在这个块中，随着这个块结束，就释放这锁，允许被访问

```c++
{
	std::lock_guard<std::mutex> lg(mtx);
	stop = true;
	g_cv.notify_all(); // 通知所有消费者
}
```



## $\textcolor{pink}{6. 线程池}$

---

> 我们之间创建线程都是单独的
>
> `std::thread t(func)`，在线程池中，就是创建了一个 `vector<std::thread> threads` **线程容器**
>
> 线程成了一个数组，即池，创建一个类的话，更加集成统一功能

```c++
class ThreadPool {
public:
    ThreadPool(const ThreadPool & other) = delete;
    ThreadPool operator=(const ThreadPool & other) = delete;

    static ThreadPool& get_instance(int thread_num) {
        std::call_once(once, [&thread_num]() {
            instance.reset(new ThreadPool(thread_num));
        });
        return *instance;
    }

    template<class F, class ...Args>
    void add_task(F && func, Args... args) {
        // 使用 function 打包函数为一个匿名 lambda 塞入线程池
        auto task = std::bind(std::forward<F>(func), std::forward<Args>(args)...);
        {
            std::unique_lock lock(this->_mtx);
            tasks.emplace(std::move(task));
        }
        this->condition.notify_one();
    }

    ~ThreadPool() {
        {
            std::unique_lock lock(this->_mtx);
            this->stop = true;
        }

        this->condition.notify_all();

        // 还在等待的线程全部都等他们执行完
        for (std::thread & t : threads) {
            if (t.joinable()) t.join();
        }
    }

private:    
    explicit ThreadPool(const int & thread_num) {
        // 往线程池的线程塞入线程函数
        for (int i = 0; i < thread_num; i++){
            // emplace 会生成一个 thread 的，所以我们填的参数其实是线程里的函数
            threads.emplace_back(&ThreadPool::thread_exec, this);       // 写法一
            // threads.emplace_back([this](){ thread_exec(); });        // 写法二
        }
    }

    void thread_exec() {
        while (true) {
            std::function<void()> task;
            {
                std::unique_lock lock(_mtx);
              	// 挂起，防止线程导致 CPU 空转
                condition.wait(lock, [this]() {return stop || !tasks.empty();});

                if (stop and tasks.empty()) return;

                if (!tasks.empty()) {
                    task = tasks.front();
                    tasks.pop();
                }
            }
            task();
        }
    }

    bool stop = false;
    std::mutex _mtx;
    static std::once_flag once;
    static std::unique_ptr<ThreadPool> instance;
    std::condition_variable condition;
    std::vector<std::thread> threads;
    std::queue<std::function<void()>> tasks;
};

int main() {
    auto &p = ThreadPool::get_instance(2);
		// 保护 cout 正常输出
    std::mutex cout_mtx;
    
    for (int i = 0; i < 100; i++) {
        p.add_task([i, &cout_mtx]() {
            std::unique_lock lock(cout_mtx);
            std::cout << "The Task " << i << " is running!\n";
        });
        std::this_thread::sleep_for(std::chrono::microseconds(1000));
    }

    return 0;
}
```

<br>

## 7. 异步并发

---

> `std::packaged_task` 和 `std::future`、`std::promise` 等构成了 C++ 中实现异步编程和并发操作的机制
>
> `std::future` 的作用
>
> - 与 `std::async` 搭配使用：用来简化异步函数调用，并获取返回结果。
>
> - 与 `std::packaged_task` 或 `std::promise` 搭配使用：实现更加灵活的任务管理和结果获取。
>
> - 多线程编程：通过 `std::future` 可以方便地获取不同线程中任务的返回值。

### 7.1 `std::async`

> 你只需要调用 `std::async`，它会帮你自动处理线程创建和任务管理，基本啥都不用你管

```c++
int func() {
    int ret = 0;

    for (size_t i = 0; i < 1000; i++) ret ++;
    return ret;
}

int main() {
    // 当 func 传递到 future 的时候，后台就开了一个线程运行 func 了
    std::future<int> future_ret = std::async(std::launch::async, func);

    // 主程序干事情
    std::cout << func() << std::endl;

    // get() 方法如果这个函数有返回值的话
    std::cout << future_ret.get() << std::endl;

    return 0;
}
```

### 7.2 `std::packaged_task`

> 和 `bind` 有一个共同点，可以包装一个可调用对象
>

```c++
#include <iostream>
#include <future>
#include <thread>

int add(int a, int b) {
    return a + b;
}

int main() {
    // 包装函数
    std::packaged_task<int(int, int)> task(add);

    // 获取 future 用来获得结果
    std::future<int> result = task.get_future();

    // 启动一个线程执行任务
    std::thread t(std::move(task), 2, 3);

    // 等待线程结束
    t.join();

    // 获取执行结果
    std::cout << "Result: " << result.get() << std::endl;

    return 0;
}
```

> [!important]
>
> 他和 `std::bind` 最大的区别就在于这里的 `std::future`，具体来说，我们 `std::bind` 丢入多线程之后，基本是在多线程之外除非靠全局变量，不然很难拿到我们的返回值
>
> 而这痛点，就直接搭配 `std::future` 解决了，执行过程相当于变成了**异步**，丢入线程执行，然后线程执行完毕，拿到返回值
>
> 你可以简单理解为，这个包装函数最大的好处就是可以

### 7.3 `std::promise` & `std::future`

> 不同线程之间值的传递：许一个线程（生产者）设置一个值，另一个线程（消费者）通过 `std::future` 来获取这个值。
>
> 它是 `std::future` 的补充，提供了一种手动设置任务结果的方式
>
> 通常使用 `std::promise` 来创建共享状态，并将它与 `std::future` 关联。
>
> 生产者线程通过 `promise` 设置值，而消费者线程通过 `future` 获取这个值

```c++
// 这个函数模拟一个耗时操作，并设置 promise 的值
void slow_function(std::promise<int>& prom) {
    std::this_thread::sleep_for(std::chrono::seconds(1));  // 模拟耗时操作
    prom.set_value(42);  // 设置任务的结果，传递给 future
}

int main() {
    // 1. 创建一个 std::promise 对象
    std::promise<int> prom;

    // 2. 通过 promise 获取关联的 future
    std::future<int> fut = prom.get_future();

    // 3. 启动一个线程并传递 promise 对象
    std::thread producer_thread(slow_function, std::ref(prom));

    // 4. 在主线程中，等待 future 获取结果
    std::cout << "Waiting for the result..." << std::endl;
    int result = fut.get();  // 阻塞，直到 promise 设置了结果
    std::cout << "Result: " << result << std::endl;  // 输出 42

    // 5. 等待生产者线程结束
    producer_thread.join();

    return 0;
}
```

### $\textcolor{pink}{7.4 优化线程池}$

> `cpp17` 需求

```cpp
class ThreadPool
{
public:
    ThreadPool(const ThreadPool &) = delete;
    ThreadPool &operator=(const ThreadPool &) = delete;

    template <class F, class... Args>
    auto add_task(F &&func, Args &&...args) -> std::future<std::invoke_result_t<F, Args...>>;

    void execute();

    void stop();

    static ThreadPool &getInstance(int threadNum)
    {
        static std::once_flag _init_flag;
        std::call_once(_init_flag, [&]()
                       { _instance.reset(new ThreadPool(threadNum)); });
        return *_instance; // ThreadPool &
    }

    ~ThreadPool();

private:
    explicit ThreadPool(int threadNum) : _stop(false)
    {
        for (size_t i = 0; i < threadNum; i++)
        {
            _thread_pool.emplace_back([this]()
                                      { execute(); });
        }
    }

    static std::unique_ptr<ThreadPool> _instance;
    std::vector<std::thread> _thread_pool;
    std::queue<std::function<void()>> _task_queue;
    std::mutex _mutex;
    std::condition_variable _cv;
    bool _stop;
};

std::unique_ptr<ThreadPool> ThreadPool::_instance = nullptr;
```

```cpp
template <class F, class... Args>
auto ThreadPool::add_task(F &&func, Args &&...args) -> std::future<std::invoke_result_t<F, Args...>>
{
    if (_stop == true)
    {
        throw std::runtime_error("ThreadPool is stopped");
    }
  
  	// 推断被封装函数的返回类型 --> C++ 17 才可以用
    using func_return_type = std::invoke_result_t<F, Args...>; 

    // ! std::packaged_task<func_return_type()> 这个 `()` 相当于 std::function<type()>
    auto task = std::make_shared<std::packaged_task<func_return_type()>>(
        std::bind(std::forward<F>(func), std::forward<Args>(args)...));

    std::future<func_return_type> result = task->get_future();

    {
        std::unique_lock<std::mutex> uni_lock(_mutex);
        _task_queue.emplace([task]()
                            { (*task)(); });
    }
    _cv.notify_one();
    return result;
}
// 启动的时候在构造函数就入线程池
void ThreadPool::execute()
{
    while (true)
    {
        std::function<void()> task;
        std::unique_lock<std::mutex> lock(_mutex);
        _cv.wait(lock, [this]()
                 { return !_task_queue.empty() || _stop; });

        // 服务器停止了就交给析构函数处理后面的，没在这里执行
        if (_stop && _task_queue.empty())
            return;

        task = std::move(_task_queue.front());
        _task_queue.pop();
        lock.unlock();
        task();
    }
}

void ThreadPool::stop()
{
    {
        std::unique_lock<std::mutex> uni_lock(_mutex);
        _stop = true;
    }
    _cv.notify_all();
}

ThreadPool::~ThreadPool()
{
    this->stop();
}
```



## 8. 原子操作

---

### `std::atomic`

> [!important]
>
> **线程安全**：`std::atomic` 确保对变量的读写操作不会被打断，从而避免多个线程并发访问时的竞争问题。
>
> **无需锁机制**：原子操作可以避免使用互斥锁（如 `std::mutex`），从而提高并发性能，因为锁通常会导致性能瓶颈。
>
> **无法替代复杂同步机制**：原子操作适合解决简单的读写问题，但是对于更复杂的同步问题（如管理多个资源、条件变量等），依然需要使用锁等同步机制。
>
> **平台依赖**：原子操作的性能依赖于底层硬件和平台，有些平台对某些原子操作的支持不够好，可能会导致性能瓶颈。

```c++
void func(std::atomic<int>& change_data) {
    for (size_t i = 0; i < 10000; i++) {
        change_data++;
    }
}

static std::atomic<int> shared_data(0);

int main() {
    // 创建两个线程
    std::thread t1(func, std::ref(shared_data));
    std::thread t2(func, std::ref(shared_data));

    // 等待线程完成
    t1.join();
    t2.join();

    // 输出结果 [atomic.load()]
    std::cout << "Final shared_data value: " << shared_data.load() << std::endl;

    return 0;
}
```

<br>

## 9. 协程

---

> [具体的携程是如何工作的还请看](D:\GitHub\Code_main\多任务的进化史.md)
>
> 我们为什么需要协程呢？
>
> > 协程不是让“这段代码能运行”，而是让它“异步 + 非阻塞”地运行，而且代码像同步一样好读。

<br>

### 1. 协程解决的痛点`<非性能考虑>`

> 假定我们有如下情况：即程序运行会遇到阻塞

```cpp
#include <iostream>
#include <thread>
#include <chrono>

void print_hello() {
    for (int i = 0; i < 5; ++i) {
        std::this_thread::sleep_for(std::chrono::seconds(1));  // 阻塞
        std::cout << "Hello after " << i + 1 << "s\n";
    }
}

```

>  如果我们不想阻塞一下输出一个，而是继续下一轮循环，我们可以把可能会阻塞的部分移交给异步函数处理：

```cpp
void start_timer(asio::io_context& ctx, int times, int count = 0) {
  	// 这里正好是一个定时的阻塞模式，我们采用这个异步定时器
    // 对于别的实际情况，我们可以 async 或者 packaged_task + future
    auto timer = std::make_shared<asio::steady_timer>(ctx, std::chrono::seconds(1));

    timer->async_wait([=, &ctx](const asio::error_code&) {
        std::cout << "Hello after " << count + 1 << "s\n";
        if (count + 1 < times) {
            start_timer(ctx, times, count + 1);  // 继续注册新的等待事件
        }
    });
}
```

> 但是这个回调却并`并不如同步那么好读`，因为是再新的一轮事件的中注册新的一轮事件
>
> 如果异步事件中完成才可以递交给另一个异步事件，多次嵌套，就变成了我们所谓的`回调地狱`了

> [!warning]
>
> 你看，我们的协程就没有在看到的代码部分有`回调函数`了，这是因为在 `co_await` 部分执行了

```cpp
awaitable<void> async_hello_timer(int times) {
    steady_timer timer(co_await asio::this_coro::executor);

    for (int i = 0; i < times; ++i) {
        timer.expires_after(1s);
        // use_awaitable: 这个异步操作不要用回调完成，帮我封装成一个 awaitable 对象
        co_await timer.async_wait(use_awaitable);  // 异步等待，不阻塞 <-- 挂起点
        std::cout << "Hello after " << i + 1 << "s\n";
    }
}
```

<br>

### 2. 如何实现一个 `co_await` 对象

> [!note]
>
> 那么这个可以被 co_await 的对象是如何实现的呢？关键是要实现下面三个成员函数：

| 方法名                                   | 作用                                            |
| ---------------------------------------- | ----------------------------------------------- |
| `bool await_ready()`                     | 是否“已经完成”，`true` 则跳过挂起，直接执行后续 |
| `void await_suspend(coroutine_handle<>)` | 挂起时执行（可异步注册）                        |
| `T await_resume()`                       | 协程恢复后，返回结果（如果有）                  |

```cpp
#include <coroutine>
#include <iostream>
#include <thread>
#include <chrono>

using namespace std::chrono_literals;

// 自定义 Awaitable 类型
struct MyAwaitable {
    int seconds;

    MyAwaitable(int s) : seconds(s) {}

    // 1. 是否准备就绪？false 表示要挂起 --> 是否需要阻塞
    bool await_ready() const noexcept {
        return false;
    }

    // 2. 启动一个线程执行我们在阻塞期间要执行的任务，然后 resume 协程 --> 当挂起时，做什么
    void await_suspend(std::coroutine_handle<> handle) {
        std::thread([this, handle]() {
            std::this_thread::sleep_for(std::chrono::seconds(seconds));
            handle.resume();  // 恢复协程
        }).detach();  // 分离线程，让主线程不等它
    }

    // 3. 这里我们无返回 --> 恢复时返回什么值
    void await_resume() const noexcept {
        // ...
    }
};
```
